/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package web.scraper;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.io.InputStreamReader;
import java.util.LinkedList;
import java.util.List;
import java.util.TreeSet;
import java.util.logging.Level;
import java.util.stream.Collectors;
import java.util.logging.Logger;

public class App {
    private static Logger logger;
    private static TreeSet<String> tree;

    public App(Logger logger) {
        App.logger = logger;
        App.tree = new TreeSet<>();
    }

    public void run() throws Exception {
        logger.info("Starting........ =D");

        List<String> seeds = getURLSeeds();
        List<List<String>> subLists = splitList(seeds, 4);

        // TreeSet and LinkedList is NOT thread safe!!!
        // Visit https://riptutorial.com/java/example/30472/treemap-and-treeset-thread-safety
        // for how to ensure thread safety using TreeSet.
        List<String> buffer1 = new LinkedList<>();
        List<String> buffer2 = new LinkedList<>();

        Crawler crawler1 = new Crawler(subLists.get(0), tree, buffer1);
        Crawler crawler2 = new Crawler(subLists.get(1), tree, buffer1);
        Crawler crawler3 = new Crawler(subLists.get(2), tree, buffer2);
        Crawler crawler4 = new Crawler(subLists.get(3), tree, buffer2);

        IndexBuilder indexBuilder = new IndexBuilder(tree, buffer1);

        Thread t11 = new Thread(crawler1);
        Thread t12 = new Thread(crawler2);
        Thread t21 = new Thread(crawler3);
        Thread t22 = new Thread(crawler4);

        t11.start();
        t12.start();
        t21.start();
        t22.start();

        Thread ib1 = new Thread(indexBuilder);
        ib1.start();

        // Spawn and start crawler thread
        // seeds can be split into different portion and give to the individual threads.
        // Crawler crawler = new Crawler(seeds, tree, buffer);
        // crawler.start();

        try {
            t11.join();
            t12.join();
            t21.join();
            t22.join();
        } catch (InterruptedException e) {
            // e.printStackTrace();
            System.err.print("Error occur!");
        }
    }

    // Read urls from seed file.
    public List<String> getURLSeeds() {
        InputStreamReader reader = new InputStreamReader(System.in);
        BufferedReader bufReader = new BufferedReader(reader);
        return bufReader.lines().collect(Collectors.toList());
    }

    public static List<List<String>> splitList(List<String> list, int numPortions) {
        int portionSize = list.size() / numPortions;

        List<List<String>> result = new LinkedList<>();
        List<String> temp = new LinkedList<>();
        int count = 0;
        int currNumPortions = 0;
        
        for (String url : list) {
            temp.add(url);
            count++;

            if (count == portionSize && currNumPortions < numPortions - 1) {
                result.add(temp);
                temp = new LinkedList<>();
                currNumPortions++;
                count = 0;
            }
        }
        result.add(temp);

        return result;
    }

    // Write the urls to the disk.
    public static void writeToDisk(TreeSet<String> tree) {
        try {
            File file = new File("./result.txt");
            file.createNewFile();

            FileWriter writer = new FileWriter(file);
            tree.forEach(url -> {
                try {
                    writer.write(url);
                    writer.write("\n");
                } catch (IOException e) {
                    e.printStackTrace();
                }
            });
            writer.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public static void main(String[] args) {
        try {
            // The following 2 line removes log from the following 2 sources.
            java.util.logging.Logger.getLogger("com.gargoylesoftware").setLevel(Level.OFF);
            java.util.logging.Logger.getLogger("org.apache.commons.httpclient").setLevel(Level.OFF);

            new App(Logger.getLogger("App")).run();
        } catch (Exception e) {
            System.err.print("Error occur!");
        } finally {
            writeToDisk(tree);
            logger.info("Done........ =D");
            System.out.println(tree.size());
        }
    }
}
